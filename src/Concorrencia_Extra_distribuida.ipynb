{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concorrência Distribuída"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local\n",
    "\n",
    "A concorrência distribuída refere-se à execução de tarefas em paralelo em várias máquinas ou nós em uma rede. Uma das bibliotecas Python mais populares para concorrência distribuída é o `Dask`. O `Dask` permite que você paralelize cálculos usando APIs familiares do Python e distribua esses cálculos em clusters.\n",
    "\n",
    "Vamos criar um exemplo simples usando `Dask` para demonstrar a concorrência distribuída no contexto de MLOps. Neste exemplo, vamos treinar vários modelos de regressão linear em diferentes subconjuntos de dados distribuídos em um cluster `Dask`.\n",
    "\n",
    "Primeiro, você precisará instalar o `Dask` e o `dask-ml`:\n",
    "\n",
    "```python\n",
    "!pip install dask[complete] dask-ml\n",
    "```\n",
    "\n",
    "Agora, vamos ao código:\n",
    "\n",
    "```python\n",
    "import dask.array as da\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from dask_ml.linear_model import LinearRegression\n",
    "from dask_ml.datasets import make_regression\n",
    "\n",
    "# Criando um cluster local e um cliente para interagir com ele\n",
    "cluster = LocalCluster(n_workers=4, threads_per_worker=1)\n",
    "client = Client(cluster)\n",
    "\n",
    "# Gerando dados distribuídos\n",
    "n_samples = 100000\n",
    "n_features = 10\n",
    "X, y = make_regression(n_samples=n_samples, n_features=n_features, chunks=n_samples//4)\n",
    "\n",
    "# Função para treinar um modelo de regressão linear\n",
    "def train_model(X, y):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    return model.coef_\n",
    "\n",
    "# Treinando modelos em paralelo nos diferentes subconjuntos de dados\n",
    "futures = client.map(train_model, X.to_delayed(), y.to_delayed())\n",
    "results = client.gather(futures)\n",
    "\n",
    "# Mostrando os coeficientes dos modelos treinados\n",
    "for i, coef in enumerate(results):\n",
    "    print(f\"Model {i} coefficients: {coef}\")\n",
    "\n",
    "# Fechando o cliente e o cluster\n",
    "client.close()\n",
    "cluster.close()\n",
    "```\n",
    "\n",
    "Neste exemplo:\n",
    "\n",
    "- Criamos um cluster `Dask` local com 4 workers.\n",
    "- Geramos dados distribuídos usando `dask_ml.datasets.make_regression`.\n",
    "- Treinamos modelos de regressão linear em paralelo nos diferentes subconjuntos de dados usando `client.map`.\n",
    "- Coletamos e exibimos os resultados.\n",
    "\n",
    "Este é um exemplo básico de concorrência distribuída usando `Dask`. Em cenários reais de MLOps, você pode ter um cluster `Dask` distribuído em várias máquinas ou na nuvem, permitindo treinar modelos ou processar dados em grande escala de forma distribuída e paralela."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Em Rede\n",
    "\n",
    "Para usar o `Dask` em um cluster distribuído com workers em diferentes máquinas, você precisa configurar um `Dask Scheduler` em uma das máquinas e `Dask Workers` nas outras. Aqui está um guia passo a passo:\n",
    "\n",
    "### 1. Instalação:\n",
    "\n",
    "Em todas as máquinas (incluindo a máquina que atuará como scheduler e as máquinas worker), instale o Dask:\n",
    "\n",
    "```bash\n",
    "pip install dask[complete]\n",
    "```\n",
    "\n",
    "### 2. Iniciar o Scheduler:\n",
    "\n",
    "Escolha uma das máquinas para ser o scheduler. Execute o seguinte comando:\n",
    "\n",
    "```bash\n",
    "dask-scheduler\n",
    "```\n",
    "\n",
    "Isso iniciará o scheduler e você verá uma saída indicando o endereço do scheduler, algo como `tcp://192.168.1.100:8786`. Anote esse endereço, pois você precisará dele para conectar os workers.\n",
    "\n",
    "### 3. Iniciar os Workers:\n",
    "\n",
    "Nas outras máquinas (que você deseja usar como workers), execute o seguinte comando:\n",
    "\n",
    "```bash\n",
    "dask-worker tcp://192.168.1.100:8786\n",
    "```\n",
    "\n",
    "Substitua `tcp://192.168.1.100:8786` pelo endereço do scheduler que você anotou anteriormente.\n",
    "\n",
    "### 4. Código Python:\n",
    "\n",
    "Agora, no seu código Python (que pode estar em qualquer máquina, incluindo uma das máquinas worker ou uma máquina separada), você se conectará ao scheduler:\n",
    "\n",
    "```python\n",
    "from dask.distributed import Client\n",
    "import dask.array as da\n",
    "from dask_ml.linear_model import LinearRegression\n",
    "from dask_ml.datasets import make_regression\n",
    "\n",
    "# Conectando ao scheduler\n",
    "client = Client('tcp://192.168.1.100:8786')  # Use o endereço do seu scheduler\n",
    "\n",
    "# Gerando dados distribuídos\n",
    "n_samples = 100000\n",
    "n_features = 10\n",
    "X, y = make_regression(n_samples=n_samples, n_features=n_features, chunks=n_samples//4)\n",
    "\n",
    "# Função para treinar um modelo de regressão linear\n",
    "def train_model(X, y):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    return model.coef_\n",
    "\n",
    "# Treinando modelos em paralelo nos diferentes subconjuntos de dados\n",
    "futures = client.map(train_model, X.to_delayed(), y.to_delayed())\n",
    "results = client.gather(futures)\n",
    "\n",
    "# Mostrando os coeficientes dos modelos treinados\n",
    "for i, coef in enumerate(results):\n",
    "    print(f\"Model {i} coefficients: {coef}\")\n",
    "\n",
    "# Fechando o cliente\n",
    "client.close()\n",
    "```\n",
    "\n",
    "Lembre-se de substituir `'tcp://192.168.1.100:8786'` pelo endereço do seu scheduler.\n",
    "\n",
    "### Notas:\n",
    "\n",
    "- Certifique-se de que as portas necessárias (por padrão, 8786 para o scheduler e 8787 para o dashboard) estejam abertas e acessíveis entre as máquinas.\n",
    "- Se você tiver problemas de conectividade, verifique as configurações de firewall e rede.\n",
    "- Para cenários de produção ou clusters maiores, você pode querer usar algo como o [Dask Kubernetes](https://kubernetes.dask.org/en/latest/) ou [Dask Yarn](https://yarn.dask.org/en/latest/) para gerenciar e escalar seu cluster Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
